import sys
from pathlib import Path
import torch
import torch.nn as nn
from torchvision import transforms, models
from PIL import Image

CLOUD_DESC = {
    "Ac": "ê³ ì ìš´: ì¤‘ì¸µì— ë‚˜íƒ€ë‚˜ëŠ” ì‘ì€ êµ¬ë¦„ ë©ì–´ë¦¬ë“¤ì´ ë¬¼ê²°ì²˜ëŸ¼ ë°°ì—´ëœ êµ¬ë¦„",
    "As": "ê³ ì¸µìš´: í•˜ëŠ˜ì„ ë„“ê²Œ ë®ëŠ” íšŒìƒ‰ ë˜ëŠ” í‘¸ë¥¸ë¹›ì˜ ì–‡ì€ ì¸µêµ¬ë¦„",
    "Cb": "ì ë€ìš´: ê°•í•œ ìƒìŠ¹ê¸°ë¥˜ë¡œ í˜•ì„±ë˜ë©° ì†Œë‚˜ê¸°Â·ë‡Œìš°ë¥¼ ë™ë°˜í•˜ëŠ” êµ¬ë¦„",
    "Cc": "ê¶Œì ìš´: ë§¤ìš° ë†’ì€ ê³ ë„ì—ì„œ ìƒê¸°ëŠ” ì‘ì€ ë¹„ëŠ˜ ëª¨ì–‘ì˜ êµ¬ë¦„",
    "Ci": "ê¶Œìš´: ê¹ƒí„¸ì²˜ëŸ¼ ê°€ëŠ˜ê³  í° ì‹¤ ëª¨ì–‘ì˜ ìƒì¸µ êµ¬ë¦„",
    "Cs": "ê¶Œì¸µìš´: íƒœì–‘Â·ë‹¬ ì£¼ìœ„ì— í—¤ì¼ë¡œë¥¼ ë§Œë“œëŠ” ì–‡ì€ ë§‰ í˜•íƒœì˜ êµ¬ë¦„",
    "Ct": "ë¹„í–‰ìš´: í•­ê³µê¸° ë°°ê¸°ê°€ìŠ¤ì— ì˜í•´ í˜•ì„±ëœ ì¸ê³µ êµ¬ë¦„",
    "Cu": "ì ìš´: ë‚ ì”¨ê°€ ì¢‹ì„ ë•Œ í”íˆ ë³´ì´ëŠ” ë­‰ê²Œêµ¬ë¦„",
    "Ns": "ë‚œì¸µìš´: ì¥ì‹œê°„ ì§€ì†ë˜ëŠ” ë¹„ë‚˜ ëˆˆì„ ë‚´ë¦¬ê²Œ í•˜ëŠ” ë‘êº¼ìš´ ì¸µêµ¬ë¦„",
    "Sc": "ì¸µì ìš´: ë‚®ì€ ê³ ë„ì—ì„œ ë„“ê²Œ í¼ì§„ ë©ì–´ë¦¬í˜• êµ¬ë¦„",
    "St": "ì¸µìš´: ì•ˆê°œì²˜ëŸ¼ í•˜ëŠ˜ì„ ë®ëŠ” ë§¤ìš° ë‚®ì€ êµ¬ë¦„",
}

PROJECT_DIR = Path(__file__).resolve().parent
DEFAULT_MODEL = PROJECT_DIR / "outputs" / "cloud_model_fast.pt"  # fallback

device = "cuda" if torch.cuda.is_available() else "cpu"


def build_model(arch: str, num_classes: int):
    arch = (arch or "").lower()
    if arch == "convnext_tiny":
        m = models.convnext_tiny(weights=None)
        m.classifier[2] = nn.Linear(m.classifier[2].in_features, num_classes)
        return m
    # fallback: resnet18
    m = models.resnet18(weights=None)
    m.fc = nn.Linear(m.fc.in_features, num_classes)
    return m


def load_checkpoint(model_path: Path):
    ckpt = torch.load(model_path, map_location=device)

    # fast model format
    if "model" in ckpt and "classes" in ckpt:
        classes = ckpt["classes"]
        arch = "resnet18"
        img_size = 192
        model = build_model(arch, len(classes))
        model.load_state_dict(ckpt["model"])
        return model, classes, img_size, arch

    # gpu model format
    classes = ckpt["classes"]
    img_size = int(ckpt.get("img_size", 224))
    arch = ckpt.get("arch", "convnext_tiny")
    model = build_model(arch, len(classes))
    model.load_state_dict(ckpt["model_state"])
    return model, classes, img_size, arch


def make_tf(img_size: int):
    return transforms.Compose([
        transforms.Resize(int(img_size * 1.15)),
        transforms.CenterCrop(img_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
    ])


def predict_image(model, classes, tf, img_path: Path, topk=3):
    img = Image.open(img_path).convert("RGB")
    x = tf(img).unsqueeze(0).to(device)

    model.eval()
    with torch.no_grad():
        logits = model(x)
        probs = torch.softmax(logits, dim=1)[0]
    values, indices = probs.topk(topk)

    results = []
    for v, i in zip(values, indices):
        label = classes[int(i)]
        results.append((label, float(v)))
    return results


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python predict.py <image_path> [model_path(optional)]")
        sys.exit(1)

    img_path = Path(sys.argv[1])
    model_path = Path(sys.argv[2]) if len(sys.argv) >= 3 else DEFAULT_MODEL

    model, classes, img_size, arch = load_checkpoint(model_path)
    model.to(device)
    tf = make_tf(img_size)

    results = predict_image(model, classes, tf, img_path, topk=3)

    print(f"\nğŸŒ¥ï¸ Model: {arch} | img_size={img_size} | device={device}")
    print("ğŸŒ¥ï¸ êµ¬ë¦„ ë¶„ë¥˜ ê²°ê³¼ (Top-3):\n")
    for rank, (label, prob) in enumerate(results, 1):
        desc = CLOUD_DESC.get(label, "ì„¤ëª… ì—†ìŒ")
        print(f"{rank}. {label} ({prob*100:.1f}%)")
        print(f"   â†’ {desc}\n")
